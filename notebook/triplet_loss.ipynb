{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAD for Wave by Triplet Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../src')\n",
    "\n",
    "import utils\n",
    "\n",
    "from trainer import fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cuda = False\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path().cwd().parent/'data'\n",
    "raw_data_dir = data_dir/'external'/'ESC-50'\n",
    "processed_data_dir = data_dir/'processed'/'ESC-50'\n",
    "\n",
    "model_path = Path().cwd().parent/'models'/'model.pth'\n",
    "embeddingnet_path = Path().cwd().parent/'models'/'embeddingnet.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = raw_data_dir/'meta'/'esc50.csv'\n",
    "audio_dir = raw_data_dir/'audio'\n",
    "spectrogram_dir = processed_data_dir/'spectrogram'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata_path = processed_data_dir/'metadata_train.csv'\n",
    "valid_metadata_path = processed_data_dir/'metadata_valid.csv'\n",
    "test_metadata_path = processed_data_dir/'metadata_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available() and (not no_cuda)\n",
    "device = 'cuda' if use_cuda else 'cpu'\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "print('device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sp(x, n_fft=512, hop_length=256):\n",
    "    # change wave data to stft\n",
    "    stft = librosa.stft(x, n_fft=n_fft, hop_length=hop_length)\n",
    "    sp = librosa.amplitude_to_db(np.abs(stft))\n",
    "    return sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESC50Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, metadata_path, audio_dir, spectrogram_dir, transform=None,):\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.metadata = pd.read_csv(str(metadata_path))\n",
    "        self.audio_dir = Path(audio_dir)\n",
    "        self.spectrogram_dir = Path(spectrogram_dir)\n",
    "        \n",
    "        self.label_data = None\n",
    "        self.labels = set()\n",
    "        self.label2indices = {}\n",
    "\n",
    "        self.build()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.load_audio(index)\n",
    "\n",
    "    def load_audio(self, index):\n",
    "        fname = self.metadata.at[index, 'filename']\n",
    "        fpath = self.audio_dir/fname\n",
    "        x, fs = librosa.load(str(fpath))\n",
    "        return x, fs\n",
    "    \n",
    "    def load_spectrogram(self, index):\n",
    "        fname = self.metadata.at[index, 'fname']+'.npy'\n",
    "        fpath = self.spectrogram_dir/fname\n",
    "        x = np.load(str(fpath))\n",
    "        return x\n",
    "    \n",
    "    def load_label(self, index):\n",
    "        label = self.metadata.at[index, 'target']\n",
    "        return label\n",
    "    \n",
    "    def build_label_data(self):\n",
    "        label_data = self.metadata.loc[:, ['target', 'category']].drop_duplicates()\n",
    "        label_data = label_data.sort_values(by=['target'], ascending=True)\n",
    "        label_data = label_data.reset_index(drop=True)\n",
    "\n",
    "        label_data['number'] = 0\n",
    "        label2indices = {}\n",
    "        for i, target in enumerate(label_data['target']):\n",
    "            data = self.metadata.query('target == @target')\n",
    "            label_data.loc[i, 'number'] = len(data)\n",
    "            label2indices[target] = data.index.values.tolist()\n",
    "\n",
    "        self.labels = set(label2indices.keys())\n",
    "        self.label_data = label_data\n",
    "        self.label2indices = label2indices\n",
    "        return label_data, label2indices\n",
    "\n",
    "    def build_spectrogram(self):\n",
    "        self.metadata['fname'] = ''\n",
    "        for index in range(len(self.metadata)):\n",
    "            audio_file_path = self.audio_dir/self.metadata.at[index, 'filename']\n",
    "            fname = audio_file_path.stem\n",
    "            self.metadata.at[index, 'fname'] = fname\n",
    "\n",
    "            fname += '.npy'\n",
    "            spec_file_path = self.spectrogram_dir/fname\n",
    "            if not spec_file_path.exists():\n",
    "                x, fs = self.load_audio(index)\n",
    "                spec = calculate_sp(x, n_fft=512, hop_length=256)\n",
    "                np.save(str(spec_file_path), spec)\n",
    "        return\n",
    "\n",
    "    def build(self):\n",
    "        self.build_label_data()\n",
    "        self.build_spectrogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESC50DatasetTriplet(ESC50Dataset):\n",
    "    def __init__(self, metadata_path, audio_dir, spectrogram_dir, transform=None,):\n",
    "        super(ESC50DatasetTriplet, self).__init__(metadata_path, audio_dir, spectrogram_dir, transform)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        spec_anc, label_anc = self.load_spectrogram(index), self.load_label(index)\n",
    "        \n",
    "        # positive sampling\n",
    "        indices_pos = self.label2indices[label_anc]\n",
    "        index_pos = index\n",
    "        if len(indices_pos) > 1:\n",
    "            while index_pos == index:\n",
    "                index_pos = np.random.choice(indices_pos)\n",
    "        spec_pos = self.load_spectrogram(index_pos)\n",
    "\n",
    "        # negative sampling\n",
    "        labels_neg = list(self.labels - set([label_anc]))\n",
    "        label_neg = np.random.choice(labels_neg)\n",
    "        index_neg = np.random.choice(self.label2indices[label_neg])\n",
    "        spec_neg = self.load_spectrogram(index_neg)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            spec_anc = self.transform(spec_anc)\n",
    "            spec_pos = self.transform(spec_pos)\n",
    "            spec_neg = self.transform(spec_neg)\n",
    "\n",
    "        return (spec_anc, spec_anc, spec_neg), []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pos_samples, neg_samples, device):\n",
    "    \"\"\" pos_samples: Distance between positive pair\n",
    "        neg_samples: Distance between negative pair\n",
    "    \"\"\"\n",
    "    margin = 0\n",
    "    pred = (pos_samples - neg_samples + margin).cpu().data\n",
    "    acc = (pred > 0).sum()*1.0 / pos_samples.size()[0]\n",
    "    acc = torch.from_numpy(np.array([acc], np.float32))\n",
    "    acc = acc.to(device)\n",
    "    return Variable(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Triplet loss\n",
    "    Takes embeddings of an anchor sample, a positive sample and a negative sample\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative, size_average=True):\n",
    "        distance_positive = (anchor - positive).pow(2).sum(1)  # .pow(.5)\n",
    "        distance_negative = (anchor - negative).pow(2).sum(1)  # .pow(.5)\n",
    "        losses = F.relu(distance_positive - distance_negative + self.margin)\n",
    "        return losses.mean() if size_average else losses.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_padding_size(i, o, k, s=1, d=1):\n",
    "    p = int(((o-1)*s + k + (k-1)*(d-1) - i) / 2)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.convnet_1 = self._make_conv_net(4)\n",
    "        self.convnet_2 = self._make_conv_net(8)\n",
    "        self.convnet_3 = self._make_conv_net(16)\n",
    "        self.convnet_4 = self._make_conv_net(32)\n",
    "\n",
    "        p = calc_padding_size\n",
    "        i0, i1 = input_size\n",
    "        self.convnet = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64, out_channels=128,\n",
    "                kernel_size=(1, 8), stride=(1, 8),\n",
    "                padding=(p(i0, i0, 1, 1), p(i1, i1, 8, 2))\n",
    "                ),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=128, out_channels=128,\n",
    "                kernel_size=(8, 1), stride=(2, 1),\n",
    "                padding=(p(i0, i0, 8, 2), p(i1, i1, 1, 1))\n",
    "                ),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            #nn.AvgPool2d(6, ceil_mode=True),\n",
    "            )\n",
    "\n",
    "        # global average pooling\n",
    "        self.pooling = lambda x: F.avg_pool2d(x, kernel_size=x.size()[2:])\n",
    "\n",
    "        \n",
    "        #self.fc = nn.Sequential(\n",
    "        #    nn.Dropout(0.5),\n",
    "        #    nn.Linear(128, output_size),\n",
    "        #    )\n",
    "    \n",
    "    def _make_conv_net(self, filter_size):        \n",
    "        p = calc_padding_size\n",
    "        i0, i1 = input_size\n",
    "\n",
    "        convnet = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1, out_channels=32,\n",
    "                kernel_size=(1, filter_size), stride=(1, 2),\n",
    "                padding=(p(i0, i0, 1, 1), p(i1, i1, filter_size, 2))\n",
    "                ),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=32, out_channels=32,\n",
    "                kernel_size=(filter_size, 1), stride=(2, 1),\n",
    "                padding=(p(i0, i0, filter_size, 2), p(i1, i1, 1, 1))\n",
    "                ),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=32, out_channels=64,\n",
    "                kernel_size=(1, filter_size), stride=(1, 2),\n",
    "                padding=(p(i0, i0, 1, 1), p(i1, i1, filter_size, 2))\n",
    "                ),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=64, out_channels=64,\n",
    "                kernel_size=(filter_size, 1), stride=(2, 1),\n",
    "                padding=(p(i0, i0, filter_size, 2), p(i1, i1, 1, 1))\n",
    "                ),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        return convnet\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedding = self.convnet_1(x)\n",
    "        embedding += self.convnet_2(x)\n",
    "        embedding += self.convnet_3(x)\n",
    "        embedding += self.convnet_4(x)\n",
    "        embedding = self.convnet(embedding)\n",
    "        embedding = self.pooling(embedding)\n",
    "        embedding = embedding.view(embedding.size()[0], -1)\n",
    "        #embedding = self.fc(embedding)\n",
    "        #embedding /= embedding.pow(2).sum(1, keepdim=True).sqrt()  # normalize\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, embedding_net):\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.embedding_net = embedding_net\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        embed_anc = self.embedding_net(anchor)\n",
    "        embed_pos = self.embedding_net(positive)\n",
    "        embed_neg = self.embedding_net(negative)\n",
    "        return embed_anc, embed_pos, embed_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (257, 431)\n",
    "output_size = 128\n",
    "\n",
    "margin = 1.\n",
    "\n",
    "lr = 1e-5\n",
    "weight_decay = 1e-6\n",
    "\n",
    "batch_size = 2\n",
    "n_epochs = 2\n",
    "\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = ESC50DatasetTriplet(\n",
    "    train_metadata_path, audio_dir, spectrogram_dir, transform,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_valid = ESC50DatasetTriplet(\n",
    "    valid_metadata_path, audio_dir, spectrogram_dir, transform,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_valid = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_net = EmbeddingNet(input_size, output_size).to(device)\n",
    "model = TripletNet(embedding_net).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = TripletLoss(margin)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [0/1600 (0%)]\tLoss: 0.943010\n",
      "Train: [200/1600 (12%)]\tLoss: 0.918794\n",
      "Train: [400/1600 (25%)]\tLoss: 0.716528\n",
      "Train: [600/1600 (38%)]\tLoss: 0.577031\n",
      "Train: [800/1600 (50%)]\tLoss: 0.537521\n",
      "Train: [1000/1600 (62%)]\tLoss: 0.453561\n",
      "Train: [1200/1600 (75%)]\tLoss: 0.420107\n",
      "Train: [1400/1600 (88%)]\tLoss: 0.429307\n",
      "Epoch: 1/2. Train set: Average loss: 0.5609\n",
      "Epoch: 1/2. Validation set: Average loss: 0.8099\n",
      "Train: [0/1600 (0%)]\tLoss: 0.954583\n",
      "Train: [200/1600 (12%)]\tLoss: 0.400231\n",
      "Train: [400/1600 (25%)]\tLoss: 0.383308\n",
      "Train: [600/1600 (38%)]\tLoss: 0.370958\n",
      "Train: [800/1600 (50%)]\tLoss: 0.376195\n",
      "Train: [1000/1600 (62%)]\tLoss: 0.247889\n"
     ]
    }
   ],
   "source": [
    "fit(\n",
    "    dataloader_train,\n",
    "    dataloader_valid,\n",
    "    model, loss_function, optimizer, scheduler,\n",
    "    n_epochs, use_cuda, log_interval,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), str(model_path))\n",
    "torch.save(embedding_net.state_dict(), str(embeddingnet_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(str(model_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
